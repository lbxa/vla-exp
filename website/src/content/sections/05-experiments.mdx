---
title: "Experiments & Results"
order: 5
description: "Experimental setup, results, and analysis"
---

import Figure from '../../components/Figure.astro';
import VideoPlayer from '../../components/VideoPlayer.astro';
import YouTubePlayer from '../../components/YouTubePlayer.astro';

## Experiments & Results

**Copy your experiments and results section from Notion here.**

### Experimental Setup

- **Datasets:** Description of datasets used
- **Baselines:** Comparison methods
- **Hardware:** Computational resources
- **Hyperparameters:** Key settings

### Main Results

#### Quantitative Results

*Table 1: Comparison of different methods on the main benchmark. Higher values are better for accuracy and F1-score (↑), lower values are better for training time and memory usage (↓). Our method achieves the best performance across all metrics.*

| Method | Accuracy ↑ | F1-Score ↑ | Training Time ↓ | Memory Usage ↓ |
|--------|-----------|-----------|----------------|----------------|
| Baseline | 0.756 | 0.723 | 4.2h | 8.1GB |
| Method A | 0.782 | 0.751 | 3.8h | 7.3GB |
| Method B | 0.798 | 0.773 | 3.1h | 6.9GB |
| **Ours** | **0.823** | **0.801** | **2.7h** | **6.2GB** |

<Figure 
  src="/images/train-loss.svg" 
  caption="Figure 4: Training loss curves comparing different optimization strategies"
  alt="Training loss comparison"
/>

#### Qualitative Results

The qualitative analysis reveals significant improvements in edge cases and complex scenarios. Our method demonstrates superior robustness compared to baseline approaches.

### Ablation Studies

We conduct ablation studies to understand the contribution of each component. The performance gain $\Delta$ is measured as:

$$
\Delta = \frac{\text{Acc}_{\text{full}} - \text{Acc}_{\text{ablated}}}{\text{Acc}_{\text{ablated}}} \times 100\%
$$

*Table 2: Ablation study results. $\Delta$ represents the relative performance drop when each component is removed.*

| Component Removed | Accuracy | $\Delta$ (%) | Impact |
|------------------|----------|-------------|---------|
| None (Full Model) | 0.823 | - | Baseline |
| Regularization | 0.798 | -3.0% | Moderate |
| Adaptive LR | 0.781 | -5.1% | High |
| Data Augmentation | 0.756 | -8.1% | Critical |

Analysis of different components of our approach:

- **Regularization:** Provides moderate improvement by preventing overfitting
- **Adaptive Learning Rate:** Critical for convergence, shows $5.1\%$ performance gain
- **Data Augmentation:** Most important component with $8.1\%$ improvement

### Demo Videos

<YouTubePlayer 
  videoId="9bZkp7q19f0" 
  caption="Demo 1: Experimental results on benchmark dataset"
  autoplay={false}
/>

<YouTubePlayer 
  videoId="jNQXAC9IVRw" 
  caption="Demo 2: Comparison with baseline methods"
  autoplay={false}
/>

### Performance Analysis

Detailed analysis of performance across different conditions:

- **Scenario 1:** Results and analysis
- **Scenario 2:** Results and analysis
- **Edge Cases:** How your method handles challenging cases